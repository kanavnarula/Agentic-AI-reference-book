{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9ff064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun, YouTubeSearchTool\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a9d5c",
   "metadata": {},
   "source": [
    "## Wikipedia Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95334eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_api_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a4d031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c1d742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6194f836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0698c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Milvus (vector database)\\nSummary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service called Zilliz Cloud.\\nMilvus is an open-source project under the LF AI & Data Foundation and is distributed under the Apache License 2.0.\\n\\nPage: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector\\'s position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\\nThese feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\\nVector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\\nVector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\\n\\nPage: Markov chain\\nSummary: In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). Markov processes are named in honor of the Russian mathematician Andrey Markov.\\nMarkov chains have many applications as statistical models of real-world processes. They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.\\nThe adjectives Markovian and Markov are used to describe something that is related to a Markov process.\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_tool.invoke({\"query\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e7f64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Milvus (vector database)\\nSummary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service called Zilliz Cloud.\\nMilvus is an open-source project under the LF AI & Data Foundation and is distributed under the Apache License 2.0.\\n\\nPage: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector\\'s position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\\nThese feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\\nVector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\\nVector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\\n\\nPage: Markov chain\\nSummary: In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). Markov processes are named in honor of the Russian mathematician Andrey Markov.\\nMarkov chains have many applications as statistical models of real-world processes. They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.\\nThe adjectives Markovian and Markov are used to describe something that is related to a Markov process.\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_tool.invoke(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e6f44",
   "metadata": {},
   "source": [
    "## You Tube Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46bef422",
   "metadata": {},
   "outputs": [],
   "source": [
    "you_tube_tool = YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d52f6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube_search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "you_tube_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c673a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "you_tube_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43ac6e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "you_tube_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f93a5210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=aywZrzNaKjs&t=38s&pp=ygUQTGFuZ2NoYWluIGJhc2ljcw%3D%3D', 'https://www.youtube.com/watch?v=nAmC7SoVLd8&t=22s&pp=ygUQTGFuZ2NoYWluIGJhc2ljcw%3D%3D']\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "you_tube_tool.invoke(\"Langchain basics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331716d3",
   "metadata": {},
   "source": [
    "## Tavily Search Engine Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc1224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6p/ddx1yx2j547512yh8wlgztw00000gn/T/ipykernel_15442/2261976334.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(api_key=key)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv(\"TAVILY_API_KEY\")\n",
    "tavily_tool = TavilySearchResults(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d992ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tavily_search_results_json'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d39c8801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef40bd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'search query to look up',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08e03cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What Is LangChain? | IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/langchain',\n",
       "  'content': 'The most basic chain is LLMChain. It simply calls a model and prompt template for that model. For example, imagine you saved a prompt as “ExamplePrompt” and wanted to run it against Flan-T5. You can import LLMChain from langchain.chains, then define chain_example = LLMChain(llm = flan-t5, prompt = ExamplePrompt). To run the chain for a given input, you simply call chain_example.run(“input”). [...] LangChain is an open source orchestration framework for application development using large language models (LLMs). Available in both Python- and Javascript-based libraries, LangChain’s tools and APIs simplify the process of building LLM-driven applications like chatbots and AI agents. [...] LangChain is essentially a library of abstractions for Python and Javascript, representing common steps and concepts necessary to work with language models. These modular components—like functions and object classes—serve as the building blocks of generative AI programs. They can be “_chained_” together to create applications, minimizing the amount of code and fine understanding required to execute complex NLP tasks. Though LangChain’s abstracted approach may limit the extent to which an expert',\n",
       "  'score': 0.7722049},\n",
       " {'title': 'langchain-ai/langchain: Build context-aware reasoning applications',\n",
       "  'url': 'https://github.com/langchain-ai/langchain',\n",
       "  'content': 'LangChain is a framework for building LLM-powered applications. It helps you chain\\ntogether interoperable components and third-party integrations to simplify AI\\napplication development — all while future-proofing decisions as the underlying\\ntechnology evolves.\\n\\n```\\npip install -U langchain\\n```\\n\\nTo learn more about LangChain, check out\\nthe docs. If you’re looking for more\\nadvanced customization or agent orchestration, check out\\nLangGraph, our framework for building\\ncontrollable agent workflows. [...] ## Why use LangChain?\\n\\nLangChain helps developers build applications powered by LLMs through a standard\\ninterface for models, embeddings, vector stores, and more.\\n\\nUse LangChain for: [...] - Real-time data augmentation. Easily connect LLMs to diverse data sources and\\n  external / internal systems, drawing from LangChain’s vast library of integrations with\\n  model providers, tools, vector stores, retrievers, and more.\\n- Model interoperability. Swap models in and out as your engineering team\\n  experiments to find the best choice for your application’s needs. As the industry\\n  frontier evolves, adapt quickly — LangChain’s abstractions keep you moving without\\n  losing momentum.',\n",
       "  'score': 0.7040996},\n",
       " {'title': 'Introduction | 🦜️   LangChain',\n",
       "  'url': 'https://python.langchain.com/docs/introduction/',\n",
       "  'content': \"`langchain-core`: Base abstractions for chat models and other components.\\n   Integration packages (e.g. `langchain-openai`, `langchain-anthropic`, etc.): Important integrations have been split into lightweight packages that are co-maintained by the LangChain team and the integration developers.\\n   `langchain`: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.\\n   `langchain-community`: Third-party integrations that are community maintained. [...] Image 3: Diagram outlining the hierarchical organization of the LangChain framework, displaying the interconnected parts across multiple layers.\\nLangChain implements a standard interface for large language models and related technologies, such as embedding models and vector stores, and integrates with hundreds of providers. See the integrations page for more.\\n\\nSelect chat model:\\n\\nGoogle Gemini▾ [...] Architecture\\u200b\\n-----------------------------------------------------------------------------------------------------------\\n\\nThe LangChain framework consists of multiple open-source libraries. Read more in the Architecture page.\",\n",
       "  'score': 0.68064564},\n",
       " {'title': 'LLM Powered Applications Building with LangChain | by Bijit Ghosh',\n",
       "  'url': 'https://medium.com/@bijit211987/llm-powered-applications-building-with-langchain-cad4032d733c',\n",
       "  'content': 'A basic use of LLMs like Codex is generating coherent text given a prompt. This powers capabilities like natural language generation and semantic search.\\n\\nFor example, we can build a simple blog post generator:\\n\\nimport langchain\\n\\nai = langchain.OpenAI()def generate\\\\_post(title, author):  \\n    \\n  prompt = f\"Generate a blog post on \\'{title}\\' by {author}:\"  \\n    \\n  return ai.generate(prompt)print(generate\\\\_post(\"Using LangChain\", \"Bijit Ghosh\")) [...] Semantic code search over GitHub dataset.\\n\\nToxicity Classifier\\n\\nClassify online comments as toxic using jurassic.\\n\\nData Explorer\\n\\nQuery databases using natural language.\\n\\nLive Coder\\n\\nConvert natural language requests to Python code.\\n\\nArticle Generator\\n\\nGenerate blog posts from headline and author.\\n\\nThese provide reusable patterns for building real-world LangChain applications.\\n\\nIn addition, these tools leverage LangChain under the hood for LLM integrations: [...] Automated song writing\\n   Interactive fiction and text adventure games\\n   ML-assisted coding and content creation\\n   Developing premises, characters, and plots for books/films\\n\\nCreativity-enhancing tools provide limitless possibilities for artistic expression using LLMs.\\n\\nChaining Multiple Models\\n========================\\n\\nA key capability of LangChain is its ability to chain different language models together into a pipeline.',\n",
       "  'score': 0.60694176},\n",
       " {'title': 'LangChain Master Class For Beginners 2024 [+20 Examples ...',\n",
       "  'url': 'https://www.youtube.com/watch?v=yF9kGESAi3M',\n",
       "  'content': \"outline for this tutorial so that you can understand what you're getting into and so that you can get the most out of this tutorial so to start off the first thing we're going to do is set up the environment on your local computer so that you can run the over 20 different Lang chain examples that I've built for you guys from there we're going to start diving deep into each of the core components of Lang chain so to start off we're going to start working with chat models and this is basically [...] crash course on poetry and setting up visual studio code and after that let's dive back into the video all right so it's time for us to dive into our first core component of Lang chain which is going to be chat models now what the heck are chat models and what do they do well a chat model is basically Lang Chain's way of making it super easy for us developers to talk to all the different large language models out there like chat BT claw Gemini and a bunch more they abstract away all the [...] were doing rag retrieval augmented generation so we're going to do a huge Deep dive into this one and then finally what we're going to do to wrap up this tutorial is we're going to do a deep dive into agents and tools and as you can see we're going to start off with the basics and then we're going to do a deep dive into agents which are are basically just you know chat models however they can make decisions on their own and act it's super cool how it works and then we're going to do a deep dive\",\n",
       "  'score': 0.58123237}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.invoke(\"Langchain basics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82426457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'NVIDIA Corporation - Stock Quote & Chart',\n",
       "  'url': 'https://investor.nvidia.com/stock-info/stock-quote-and-chart/default.aspx',\n",
       "  'content': '| July 09, 2025 | $162.88 |\\n| July 08, 2025 | $160 |\\n| July 07, 2025 | $158.24 |\\n| July 03, 2025 | $159.34 |\\n| July 02, 2025 | $157.25 |\\n| July 01, 2025 | $153.3 |\\n| June 30, 2025 | $157.99 |\\n| June 27, 2025 | $157.75 |\\n| June 26, 2025 | $155.02 |\\n| June 25, 2025 | $154.31 |\\n| June 24, 2025 | $147.9 |\\n| June 23, 2025 | $144.17 |\\n| June 20, 2025 | $143.85 |\\n| June 18, 2025 | $145.48 |\\n| June 17, 2025 | $144.12 |\\n| June 16, 2025 | $144.69 |\\n| June 13, 2025 | $141.97 |\\n| June 12, 2025 | $145 | [...] XNAS:NVDA,NASD:NVDA historical stock data| Stock Date | Stock Price |\\n| --- | --- |\\n| July 30, 2025 | $179.27 |\\n| July 29, 2025 | $175.51 |\\n| July 28, 2025 | $176.75 |\\n| July 25, 2025 | $173.5 |\\n| July 24, 2025 | $173.74 |\\n| July 23, 2025 | $170.78 |\\n| July 22, 2025 | $167.03 |\\n| July 21, 2025 | $171.38 |\\n| July 18, 2025 | $172.41 |\\n| July 17, 2025 | $173 |\\n| July 16, 2025 | $171.37 |\\n| July 15, 2025 | $170.7 |\\n| July 14, 2025 | $164.07 |\\n| July 11, 2025 | $164.92 |\\n| July 10, 2025 | $164.1 | [...] | May 15, 2025 | $134.83 |\\n| May 14, 2025 | $135.34 |\\n| May 13, 2025 | $129.93 |\\n| May 12, 2025 | $123 |\\n| May 09, 2025 | $116.65 |\\n| May 08, 2025 | $117.37 |\\n| May 07, 2025 | $117.06 |\\n| May 06, 2025 | $113.54 |\\n| May 05, 2025 | $113.82 |\\n| May 02, 2025 | $114.5 |\\n| May 01, 2025 | $111.61 |\\n| April 30, 2025 | $108.92 |\\n| April 29, 2025 | $109.02 |\\n| April 28, 2025 | $108.73 |\\n| April 25, 2025 | $111.01 |\\n| April 24, 2025 | $106.43 |\\n| April 23, 2025 | $102.71 |\\n| April 22, 2025 | $98.89 |',\n",
       "  'score': 0.92604345},\n",
       " {'title': 'NVIDIA Stock Chart — NASDAQ:NVDA Stock Price - TradingView',\n",
       "  'url': 'https://www.tradingview.com/symbols/NASDAQ-NVDA/',\n",
       "  'content': '+21.79%  1-Year \\n\\nSee all sparks\\n\\nFrequently Asked Questions\\n--------------------------\\n\\nWhat is NVIDIA stock price today?\\n\\nThe current price of NVDA is 179.27 USD — it has increased by 2.14% in the past 24 hours. Watch NVIDIA stock price performance more closely on the chart.\\n\\nWhat is NVIDIA stock ticker?\\n\\nDepending on the exchange, the stock ticker may vary. For instance, on NASDAQ exchange NVIDIA stocks are traded under the ticker NVDA.\\n\\nIs NVIDIA stock price growing? [...] What are NVIDIA stock highest and lowest prices ever?\\n\\nNVDA reached its all-time high on Jul 25, 2025 with the price of 174.72 USD, and its all-time low was 0.03 USD and was reached on Apr 26, 1999. View more price dynamics on NVDA chart. \\n\\nSee other stocks reaching their highest and lowest prices.\\n\\nHow volatile is NVDA stock? [...] NVIDIA Stock Chart — NASDAQ:NVDA Stock Price — TradingView\\n\\n===============\\n\\nMain content\\n\\n\\n\\nFull chart\\n\\n\\n\\n rose 0.8% to $176.45 in pre-market trading on July 30, recovering from a 0.7% drop, as investors anticipate earnings from Microsoft and Meta that may affect chip demand.\\n\\nNvidia, a leading AI chipmaker, saw a 1% stock rise after strong quarterly results from Microsoft and Meta, highlighting significant investments in artificial intelligence.\\n\\nAnalyze the impactAnalyze the impact',\n",
       "  'score': 0.9203972},\n",
       " {'title': 'NVIDIA Corporation (NVDA) Stock Historical Prices & Data',\n",
       "  'url': 'https://finance.yahoo.com/quote/NVDA/history/',\n",
       "  'content': '| Jan 6, 2025 | 148.59 | 152.16 | 147.82 | 149.43 | 149.41 | 265,377,400 |\\n| Jan 3, 2025 | 140.01 | 144.90 | 139.73 | 144.47 | 144.45 | 229,322,500 |\\n| Jan 2, 2025 | 136.00 | 138.88 | 134.63 | 138.31 | 138.29 | 198,247,200 |\\n| Dec 31, 2024 | 138.03 | 138.07 | 133.83 | 134.29 | 134.27 | 155,659,200 |\\n| Dec 30, 2024 | 134.83 | 140.27 | 134.02 | 137.49 | 137.47 | 167,734,700 |\\n| Dec 27, 2024 | 138.55 | 139.02 | 134.71 | 137.01 | 136.99 | 170,582,600 | [...] | Jan 24, 2025 | 148.37 | 148.97 | 141.88 | 142.62 | 142.60 | 234,657,600 |\\n| Jan 23, 2025 | 145.05 | 147.23 | 143.72 | 147.22 | 147.20 | 155,915,500 |\\n| Jan 22, 2025 | 144.66 | 147.79 | 143.67 | 147.07 | 147.05 | 237,651,400 |\\n| Jan 21, 2025 | 139.16 | 141.83 | 137.09 | 140.83 | 140.81 | 197,749,000 |\\n| Jan 17, 2025 | 136.69 | 138.50 | 135.46 | 137.71 | 137.69 | 201,188,800 |\\n| Jan 16, 2025 | 138.64 | 138.75 | 133.49 | 133.57 | 133.55 | 209,235,600 | [...] | Jun 4, 2025 | 142.19 | 142.39 | 139.54 | 141.92 | 141.91 | 167,120,800 |\\n| Jun 3, 2025 | 138.78 | 142.00 | 137.95 | 141.22 | 141.21 | 225,578,800 |\\n| Jun 2, 2025 | 135.49 | 138.12 | 135.40 | 137.38 | 137.37 | 197,663,100 |\\n| May 30, 2025 | 138.72 | 139.62 | 132.92 | 135.13 | 135.12 | 333,170,900 |\\n| May 29, 2025 | 142.25 | 143.49 | 137.91 | 139.19 | 139.18 | 369,241,900 |\\n| May 28, 2025 | 136.03 | 137.25 | 134.79 | 134.81 | 134.80 | 304,021,100 |',\n",
       "  'score': 0.9055316},\n",
       " {'title': 'NVIDIA Stock Price History - Investing.com',\n",
       "  'url': 'https://www.investing.com/equities/nvidia-corp-historical-data',\n",
       "  'content': '| Date | Price | Open | High | Low | Vol. | Change % |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| Jul 25, 2025 | 173.50 | 173.61 | 174.72 | 172.96 | 122.32M | -0.14% |\\n| Jul 24, 2025 | 173.74 | 172.44 | 173.83 | 171.30 | 128.98M | +1.73% |\\n| Jul 23, 2025 | 170.78 | 169.53 | 171.26 | 167.97 | 154.08M | +2.25% |\\n| Jul 22, 2025 | 167.03 | 171.34 | 171.39 | 164.58 | 193.11M | -2.54% |\\n| Jul 21, 2025 | 171.38 | 172.75 | 173.38 | 171.00 | 123.13M | -0.60% | [...] | Jul 18, 2025 | 172.41 | 173.64 | 174.25 | 171.26 | 146.46M | -0.34% |\\n| Jul 17, 2025 | 173.00 | 172.02 | 174.16 | 170.83 | 160.84M | +0.95% |\\n| Jul 16, 2025 | 171.37 | 171.06 | 171.75 | 168.90 | 158.83M | +0.39% |\\n| Jul 15, 2025 | 170.70 | 171.19 | 172.40 | 169.20 | 230.63M | +4.04% |\\n| Jul 14, 2025 | 164.07 | 165.37 | 165.49 | 162.02 | 136.98M | -0.52% |\\n| Jul 11, 2025 | 164.92 | 163.71 | 167.89 | 163.47 | 193.63M | +0.50% | [...] | Jul 01, 2025 | 153.30 | 156.29 | 157.20 | 151.49 | 213.14M | -2.97% |\\n| Jun 30, 2025 | 157.99 | 158.40 | 158.66 | 155.96 | 194.58M | +0.15% |\\n| Jun 27, 2025 | 157.75 | 156.04 | 158.71 | 155.26 | 263.23M | +1.76% |',\n",
       "  'score': 0.8993429},\n",
       " {'title': 'NVIDIA Corporation ( NVDA) - Price History - Digrin',\n",
       "  'url': 'https://www.digrin.com/stocks/detail/NVDA/price',\n",
       "  'content': '| Date | Adjusted price | Real price |\\n| --- | --- | --- |\\n| June 2025 | $143.94 | $143.95 |\\n| May 2025 | $135.12 | $135.13 |\\n| April 2025 | $108.91 | $108.92 |\\n| March 2025 | $108.37 | $108.38 |\\n| February 2025 | $124.90 | $124.92 |\\n| January 2025 | $120.05 | $120.07 |\\n| December 2024 | $134.27 | $134.29 |\\n| November 2024 | $138.22 | $138.25 |\\n| October 2024 | $132.73 | $132.76 |\\n| September 2024 | $121.41 | $121.44 |\\n| August 2024 | $119.33 | $119.37 |\\n| July 2024 | $116.98 | $117.02 | [...] | October 2019 | $5 | $201.02 |\\n| September 2019 | $4.33 | $174.07 |\\n| August 2019 | $4.17 | $167.51 |\\n| July 2019 | $4.19 | $168.72 |\\n| June 2019 | $4.08 | $164.23 |\\n| May 2019 | $3.37 | $135.46 |\\n| April 2019 | $4.49 | $181 |\\n| March 2019 | $4.46 | $179.56 |\\n| February 2019 | $3.83 | $154.26 |\\n| January 2019 | $3.56 | $143.75 |\\n| December 2018 | $3.31 | $133.50 |\\n| November 2018 | $4.05 | $163.43 |\\n| October 2018 | $5.22 | $210.83 |\\n| September 2018 | $6.96 | $281.02 | [...] | August 2018 | $6.95 | $280.68 |\\n| July 2018 | $6.06 | $244.86 |\\n| June 2018 | $5.86 | $236.90 |\\n| May 2018 | $6.24 | $252.19 |\\n| April 2018 | $5.56 | $224.90 |\\n| March 2018 | $5.73 | $231.59 |\\n| February 2018 | $5.99 | $242 |\\n| January 2018 | $6.08 | $245.80 |\\n| December 2017 | $4.78 | $193.50 |\\n| November 2017 | $4.96 | $200.71 |\\n| October 2017 | $5.11 | $206.81 |\\n| September 2017 | $4.42 | $178.77 |\\n| August 2017 | $4.19 | $169.44 |\\n| July 2017 | $4.01 | $162.51 |',\n",
       "  'score': 0.8810534}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.invoke(\"Stock price of NVIDIA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3295621",
   "metadata": {},
   "source": [
    "## DuckDuck Search Engine Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9c676c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duckduckgo_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7811f79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duckduckgo_search'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckduckgo_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "966eed0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckduckgo_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b6a0633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'search query to look up',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckduckgo_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3358037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Agentic-AI/venv-3-10/lib/python3.10/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Jul 23, 2025 · LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It provides a standard interface for chains, … LangChain is a framework for developing applications powered by large language models (LLMs). LangChain simplifies every stage of the LLM application lifecycle: Development: Build your … Sep 22, 2023 · In this article I will illustrate the most important concepts behind LangChain and explore some hands-on examples to show how you can leverage LangChain to create an … Apr 11, 2024 · LangChain is a popular framework for creating LLM-powered apps. It was built with these and other factors in mind, and provides a wide range of integrations with closed-source … Oct 31, 2023 · In this tutorial, we’ll examine the details of LangChain, a framework for developing applications powered by language models. We’ll begin by gathering basic concepts around the …'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckduckgo_tool.invoke(\"Langchain basics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-3-10 (3.10.15)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
